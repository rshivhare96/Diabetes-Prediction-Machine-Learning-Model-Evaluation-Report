# Diabetes Prediction using Machine Learning  

## Project Overview  
This project aims to build a **predictive model** for diabetes detection using various **machine learning algorithms**. We leverage the **Pima Indians Diabetes Dataset**, preprocess the data, train multiple models, and evaluate their performance using key metrics.  

## Dataset  
The dataset contains **768** records with **8 health-related features** and an outcome variable (**0 = No Diabetes, 1 = Diabetes**).  

### Features  
- `Pregnancies` â€“ Number of times pregnant  
- `Glucose` â€“ Plasma glucose concentration  
- `BloodPressure` â€“ Diastolic blood pressure (mm Hg)  
- `SkinThickness` â€“ Triceps skin fold thickness (mm)  
- `Insulin` â€“ 2-Hour serum insulin (mu U/ml)  
- `BMI` â€“ Body mass index (weight in kg/(height in m)^2)  
- `DiabetesPedigreeFunction` â€“ Diabetes hereditary risk factor  
- `Age` â€“ Age in years  
- `Outcome` â€“ 1 (Diabetic) or 0 (Non-diabetic)  

## Project Workflow  

### 1ï¸âƒ£ Data Preprocessing  
âœ” Checked for missing values and handled them accordingly  
âœ” Converted data types where necessary  
âœ” Standardized numerical features for better model performance  
âœ” Split dataset into **training (80%)** and **testing (20%)**  

### 2ï¸âƒ£ Model Training & Evaluation  
We trained and evaluated **four machine learning models**:  

- **Random Forest Classifier**  
- **K-Nearest Neighbors (KNN)**  
- **NaÃ¯ve Bayes Classifier**  
- **Gradient Boosting Classifier**  

## Performance Metrics  

| Model                | Accuracy | Precision | F1 Score | Recall | ROC AUC  |
|----------------------|----------|-----------|----------|--------|---------|
| Random Forest       | **72.46%** | 70.27%    | 57.78%   | 49.06% | 0.8064  |
| K-Nearest Neighbors | **73.19%** | 71.05%    | 59.34%   | 50.94% | 0.7491  |
| NaÃ¯ve Bayes         | **71.01%** | 65.12%    | 58.33%   | **52.83%** | 0.7809  |
| Gradient Boosting   | **73.91%** | **72.97%** | **60.00%** | 50.94% | **0.8173**  |

### Key Insights  
âœ… **Gradient Boosting performed best** with highest accuracy (**73.91%**) and ROC AUC (**0.8173**)  
âœ… **NaÃ¯ve Bayes had the highest recall** (52.83%), making it useful for detecting positive diabetes cases  
âœ… **KNN & Random Forest had good overall performance**  

## Next Steps  
ğŸš€ **Hyperparameter tuning** to improve model accuracy  
ğŸš€ **Feature selection & engineering** for better predictions  
ğŸš€ **Deploy the best model** as a web app or API  
ğŸš€ **Collect more data** to improve generalization  


